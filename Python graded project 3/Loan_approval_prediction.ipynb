{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tImport required libraries and read the dataset. (2)\n",
    "### 2.\tCheck the first few samples, shape, info of the data and try to familiarize yourself with different features. (2)\n",
    "### 3.\tCheck for missing values in the dataset, if present? handle them with appropriate methods and drop redundant features. (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('F:\\Python graded project 3\\loan_approval_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['property_area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace('', np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values check\n",
    "df.isnull().sum()/len(df)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.duplicated()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value treatment\n",
    "#majority of credit history has value 1 as per df.describe()\n",
    "df[\"credit_history\"].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loanamount and loan_amount_term can be replaced with median\n",
    "df[\"loanamount\"].fillna((df[\"loanamount\"].median()), inplace=True)\n",
    "df[\"loan_amount_term\"].fillna((df[\"loan_amount_term\"].median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categoricals gender,dependents,self_employed,married can be replaced with mode values\n",
    "df[\"gender\"].fillna((df[\"gender\"].mode()[0]), inplace=True)\n",
    "df[\"dependents\"].fillna((df[\"dependents\"].mode()[0]), inplace=True)\n",
    "df[\"self_employed\"].fillna((df[\"self_employed\"].mode()[0]), inplace=True)\n",
    "df[\"married\"].fillna((df[\"married\"].mode()[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values check\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loan_id is an identifier but is redundant for model building\n",
    "df=df.drop('loan_id',axis=1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\tVisualize the distribution of the target column 'loan_status' with respect to various categorical features and write your observations. (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=df.select_dtypes(include=[np.object])\n",
    "#univariate analysis of churn\n",
    "i=1\n",
    "plt.figure(figsize=(30,25))\n",
    "for feature in categorical_features:\n",
    "    plt.subplot(6,3,i)\n",
    "    sns.countplot(x=feature,hue='loan_status',data=df)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "## More males as compared to females have their loan approved\n",
    "## More married people have their loans approved\n",
    "## Most people with no dependents have their loans approved\n",
    "## Most graduates have their loans approved\n",
    "## Most Non self employed have their loans approved\n",
    "## Most people in semi urban have their loans approved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\tEncode the categorical data. (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple category datatype variables for label encoding\n",
    "label_type_variables=[i for i in df[['dependents','property_area']] ]\n",
    "le=LabelEncoder()\n",
    "def encoder(df):\n",
    "    for i in label_type_variables:\n",
    "        q=le.fit_transform(df[i].astype('str'))\n",
    "        df[i]=q\n",
    "        df[i]=df[i].astype('int')\n",
    "encoder(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the remaining categoricals\n",
    "df=pd.get_dummies(df,drop_first=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming education_not graduate\n",
    "df.rename(columns = {\"education_not graduate\":'education_notGrad'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\tSeparate the target and independent features and split the data into train and test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('loan_status_y',axis=1)\n",
    "y=df['loan_status_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 70:30\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\tBuild any classification model to predict the loan status of the customer and save your model using pickle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.function for model fit\n",
    "def fit_n_print(model,X_train,X_test,y_train,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test,pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "nb=GaussianNB()\n",
    "knn=KNeighborsClassifier()\n",
    "dt=DecisionTreeClassifier()\n",
    "rf=RandomForestClassifier()\n",
    "adb=AdaBoostClassifier()\n",
    "gb=GradientBoostingClassifier()\n",
    "\n",
    "estimators=[('rf',rf),('knn',knn),('gb',gb),('adb',adb)]\n",
    "sc=StackingClassifier(estimators=estimators, final_estimator=rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame(columns=['Accuracy'])\n",
    "for model,model_name in zip([lr,nb,knn,dt,rf,adb,gb,sc],['Logistic Regression','Naive Bayes','KNN','Decision tree','Random Forest','Ada Boost','Gradient Boost','Stacking']):\n",
    "    result.loc[model_name]=fit_n_print(model,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "## Gradient Boost gives the highest accuracy 81.62% amongst all the classifier models ## and hence can be possibly used as the \n",
    "## chosen classifier for predicting loan approval status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let us also check f1 score for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=gb.fit(X_train,y_train)\n",
    "pred=model.predict(X_test)\n",
    "f1_score=f1_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pickle the model\n",
    "filename = '/Users/moni/Documents/loan_prediction/loan_approval_predictor_final.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
